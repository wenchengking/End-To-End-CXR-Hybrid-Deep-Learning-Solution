{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone repo, install dependencies, %cd into ./yolov5 folder and check GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 15679, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "remote: Total 15679 (delta 1), reused 2 (delta 0), pack-reused 15672\u001b[K\n",
      "Receiving objects: 100% (15679/15679), 14.45 MiB | 34.57 MiB/s, done.\n",
      "Resolving deltas: 100% (10742/10742), done.\n",
      "Requirement already satisfied: gitpython>=3.1.30 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 5)) (3.1.31)\n",
      "Requirement already satisfied: matplotlib>=3.3 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 6)) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 7)) (1.24.3)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 8)) (4.7.0.72)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 9)) (9.5.0)\n",
      "Requirement already satisfied: psutil in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 10)) (5.9.5)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 12)) (2.30.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 13)) (1.10.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 14)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch>=1.7.0 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 15)) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 16)) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 17)) (4.65.0)\n",
      "Requirement already satisfied: ultralytics>=8.0.100 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 18)) (8.0.105)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 27)) (2.0.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 28)) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 42)) (65.6.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from gitpython>=3.1.30->-r yolov5/requirements.txt (line 5)) (4.0.10)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2023.5.7)\n",
      "Requirement already satisfied: filelock in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (4.5.0)\n",
      "Requirement already satisfied: sympy in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (1.12)\n",
      "Requirement already satisfied: networkx in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (2.0.0)\n",
      "Requirement already satisfied: wheel in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (0.38.4)\n",
      "Requirement already satisfied: cmake in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (3.26.3)\n",
      "Requirement already satisfied: lit in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (16.0.5)\n",
      "Requirement already satisfied: sentry-sdk in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from ultralytics>=8.0.100->-r yolov5/requirements.txt (line 18)) (1.23.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2023.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r yolov5/requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages (from sympy->torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (1.3.0)\n",
      "/nfs/home/zle2435/dl_proj/notebook/yolov5\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "# !pip install -r yolov5/requirements.txt  # install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 2.0.1+cu117 _CudaDeviceProperties(name='NVIDIA RTX A6000', major=8, minor=6, total_memory=48685MB, multi_processor_count=84)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up folder structure before training - Done"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the class:1 circle; remove these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the .txt files for class\n",
    "import os\n",
    "\n",
    "folder_path = '../data/annotated'\n",
    "delete_list = []\n",
    "\n",
    "# Walk through the directory\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            # Open the file and check the first letter\n",
    "            with open(file_path, 'r') as f:\n",
    "                first_line = f.readline().strip()\n",
    "                if first_line.startswith('1'):\n",
    "                    file_name_without_extension = os.path.splitext(file)[0]\n",
    "                    delete_list.append(file_name_without_extension)\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted file: ../data/annotated/image_349.txt\n",
      "Deleted file: ../data/annotated/image_244.jpg\n",
      "Deleted file: ../data/annotated/image_148.txt\n",
      "Deleted file: ../data/annotated/image_148.jpg\n",
      "Deleted file: ../data/annotated/image_349.jpg\n",
      "Deleted file: ../data/annotated/image_244.txt\n"
     ]
    }
   ],
   "source": [
    "# delete all files in the folder that has the substring form the delete_list\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        # Check if any substring from delete_list is present in the file name\n",
    "        if any(substring in file for substring in delete_list):\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted file: {file_path}\")\n",
    "            except OSError as e:\n",
    "                print(f\"Error deleting file: {file_path}\\nError message: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update data folder to get the right folder structure for training: train and val. 60/15/25 split for train/val/test. Since the annoted images are already randomly sampled - we just break it down to train/val/test sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir ../data/transfer_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir ../data/transfer_learning/train/\n",
    "%mkdir ../data/transfer_learning/val/\n",
    "%mkdir ../data/transfer_learning/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "# get 240 images for training and 60 images for validation\n",
    "file_path = '../data/annotated'\n",
    "train_path = '../data/transfer_learning/train/'\n",
    "val_path = '../data/transfer_learning/val/'\n",
    "test_path = '../data/transfer_learning/test/'\n",
    "\n",
    "counter = 0\n",
    "for root, dirs, files in os.walk(file_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            file_name_without_extension = os.path.splitext(file)[0]\n",
    "            file_txt = file_name_without_extension + '.txt'\n",
    "            if counter < 240:\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_txt_path = os.path.join(root, file_txt)\n",
    "                shutil.copy(file_path, train_path)\n",
    "                shutil.copy(file_txt_path, train_path)\n",
    "            elif counter < 240 + 60:\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_txt_path = os.path.join(root, file_txt)\n",
    "                shutil.copy(file_path, val_path)\n",
    "                shutil.copy(file_txt_path, val_path)\n",
    "            else: # test should have 57 images, since we dropped the 3 circles\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_txt_path = os.path.join(root, file_txt)\n",
    "                shutil.copy(file_path, test_path)\n",
    "                shutil.copy(file_txt_path, test_path)\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized 'image_352.jpg' to 640 pixels width\n",
      "Resized 'image_205.jpg' to 640 pixels width\n",
      "Resized 'image_363.jpg' to 640 pixels width\n",
      "Resized 'image_183.jpg' to 640 pixels width\n",
      "Resized 'image_307.jpg' to 640 pixels width\n",
      "Resized 'image_139.jpg' to 640 pixels width\n",
      "Resized 'image_265.jpg' to 640 pixels width\n",
      "Resized 'image_123.jpg' to 640 pixels width\n",
      "Resized 'image_166.jpg' to 640 pixels width\n",
      "Resized 'image_152.jpg' to 640 pixels width\n",
      "Resized 'image_197.jpg' to 640 pixels width\n",
      "Resized 'image_85.jpg' to 640 pixels width\n",
      "Resized 'image_92.jpg' to 640 pixels width\n",
      "Resized 'image_154.jpg' to 640 pixels width\n",
      "Resized 'image_335.jpg' to 640 pixels width\n",
      "Resized 'image_395.jpg' to 640 pixels width\n",
      "Resized 'image_302.jpg' to 640 pixels width\n",
      "Resized 'image_330.jpg' to 640 pixels width\n",
      "Resized 'image_333.jpg' to 640 pixels width\n",
      "Resized 'image_204.jpg' to 640 pixels width\n",
      "Resized 'image_285.jpg' to 640 pixels width\n",
      "Resized 'image_326.jpg' to 640 pixels width\n",
      "Resized 'image_141.jpg' to 640 pixels width\n",
      "Resized 'image_44.jpg' to 640 pixels width\n",
      "Resized 'image_153.jpg' to 640 pixels width\n",
      "Resized 'image_91.jpg' to 640 pixels width\n",
      "Resized 'image_93.jpg' to 640 pixels width\n",
      "Resized 'image_201.jpg' to 640 pixels width\n",
      "Resized 'image_160.jpg' to 640 pixels width\n",
      "Resized 'image_63.jpg' to 640 pixels width\n",
      "Resized 'image_311.jpg' to 640 pixels width\n",
      "Resized 'image_174.jpg' to 640 pixels width\n",
      "Resized 'image_324.jpg' to 640 pixels width\n",
      "Resized 'image_67.jpg' to 640 pixels width\n",
      "Resized 'image_255.jpg' to 640 pixels width\n",
      "Resized 'image_131.jpg' to 640 pixels width\n",
      "Resized 'image_127.jpg' to 640 pixels width\n",
      "Resized 'image_45.jpg' to 640 pixels width\n",
      "Resized 'image_398.jpg' to 640 pixels width\n",
      "Resized 'image_24.jpg' to 640 pixels width\n",
      "Resized 'image_49.jpg' to 640 pixels width\n",
      "Resized 'image_386.jpg' to 640 pixels width\n",
      "Resized 'image_169.jpg' to 640 pixels width\n",
      "Resized 'image_57.jpg' to 640 pixels width\n",
      "Resized 'image_73.jpg' to 640 pixels width\n",
      "Resized 'image_104.jpg' to 640 pixels width\n",
      "Resized 'image_397.jpg' to 640 pixels width\n",
      "Resized 'image_48.jpg' to 640 pixels width\n",
      "Resized 'image_132.jpg' to 640 pixels width\n",
      "Resized 'image_161.jpg' to 640 pixels width\n",
      "Resized 'image_241.jpg' to 640 pixels width\n",
      "Resized 'image_257.jpg' to 640 pixels width\n",
      "Resized 'image_66.jpg' to 640 pixels width\n",
      "Resized 'image_47.jpg' to 640 pixels width\n",
      "Resized 'image_362.jpg' to 640 pixels width\n",
      "Resized 'image_33.jpg' to 640 pixels width\n",
      "Resized 'image_329.jpg' to 640 pixels width\n",
      "Resized 'image_65.jpg' to 640 pixels width\n",
      "Resized 'image_196.jpg' to 640 pixels width\n",
      "Resized 'image_321.jpg' to 640 pixels width\n",
      "Resized 'image_107.jpg' to 640 pixels width\n",
      "Resized 'image_306.jpg' to 640 pixels width\n",
      "Resized 'image_151.jpg' to 640 pixels width\n",
      "Resized 'image_4.jpg' to 640 pixels width\n",
      "Resized 'image_108.jpg' to 640 pixels width\n",
      "Resized 'image_144.jpg' to 640 pixels width\n",
      "Resized 'image_343.jpg' to 640 pixels width\n",
      "Resized 'image_26.jpg' to 640 pixels width\n",
      "Resized 'image_170.jpg' to 640 pixels width\n",
      "Resized 'image_51.jpg' to 640 pixels width\n",
      "Resized 'image_360.jpg' to 640 pixels width\n",
      "Resized 'image_261.jpg' to 640 pixels width\n",
      "Resized 'image_16.jpg' to 640 pixels width\n",
      "Resized 'image_52.jpg' to 640 pixels width\n",
      "Resized 'image_78.jpg' to 640 pixels width\n",
      "Resized 'image_338.jpg' to 640 pixels width\n",
      "Resized 'image_350.jpg' to 640 pixels width\n",
      "Resized 'image_318.jpg' to 640 pixels width\n",
      "Resized 'image_328.jpg' to 640 pixels width\n",
      "Resized 'image_374.jpg' to 640 pixels width\n",
      "Resized 'image_223.jpg' to 640 pixels width\n",
      "Resized 'image_327.jpg' to 640 pixels width\n",
      "Resized 'image_358.jpg' to 640 pixels width\n",
      "Resized 'image_399.jpg' to 640 pixels width\n",
      "Resized 'image_94.jpg' to 640 pixels width\n",
      "Resized 'image_162.jpg' to 640 pixels width\n",
      "Resized 'image_372.jpg' to 640 pixels width\n",
      "Resized 'image_299.jpg' to 640 pixels width\n",
      "Resized 'image_392.jpg' to 640 pixels width\n",
      "Resized 'image_109.jpg' to 640 pixels width\n",
      "Resized 'image_253.jpg' to 640 pixels width\n",
      "Resized 'image_119.jpg' to 640 pixels width\n",
      "Resized 'image_222.jpg' to 640 pixels width\n",
      "Resized 'image_77.jpg' to 640 pixels width\n",
      "Resized 'image_388.jpg' to 640 pixels width\n",
      "Resized 'image_30.jpg' to 640 pixels width\n",
      "Resized 'image_246.jpg' to 640 pixels width\n",
      "Resized 'image_175.jpg' to 640 pixels width\n",
      "Resized 'image_278.jpg' to 640 pixels width\n",
      "Resized 'image_87.jpg' to 640 pixels width\n",
      "Resized 'image_202.jpg' to 640 pixels width\n",
      "Resized 'image_305.jpg' to 640 pixels width\n",
      "Resized 'image_292.jpg' to 640 pixels width\n",
      "Resized 'image_322.jpg' to 640 pixels width\n",
      "Resized 'image_56.jpg' to 640 pixels width\n",
      "Resized 'image_247.jpg' to 640 pixels width\n",
      "Resized 'image_273.jpg' to 640 pixels width\n",
      "Resized 'image_294.jpg' to 640 pixels width\n",
      "Resized 'image_60.jpg' to 640 pixels width\n",
      "Resized 'image_288.jpg' to 640 pixels width\n",
      "Resized 'image_346.jpg' to 640 pixels width\n",
      "Resized 'image_114.jpg' to 640 pixels width\n",
      "Resized 'image_180.jpg' to 640 pixels width\n",
      "Resized 'image_75.jpg' to 640 pixels width\n",
      "Resized 'image_207.jpg' to 640 pixels width\n",
      "Resized 'image_79.jpg' to 640 pixels width\n",
      "Resized 'image_250.jpg' to 640 pixels width\n",
      "Resized 'image_126.jpg' to 640 pixels width\n",
      "Resized 'image_145.jpg' to 640 pixels width\n",
      "Resized 'image_118.jpg' to 640 pixels width\n",
      "Resized 'image_298.jpg' to 640 pixels width\n",
      "Resized 'image_176.jpg' to 640 pixels width\n",
      "Resized 'image_105.jpg' to 640 pixels width\n",
      "Resized 'image_146.jpg' to 640 pixels width\n",
      "Resized 'image_359.jpg' to 640 pixels width\n",
      "Resized 'image_53.jpg' to 640 pixels width\n",
      "Resized 'image_354.jpg' to 640 pixels width\n",
      "Resized 'image_100.jpg' to 640 pixels width\n",
      "Resized 'image_84.jpg' to 640 pixels width\n",
      "Resized 'image_96.jpg' to 640 pixels width\n",
      "Resized 'image_83.jpg' to 640 pixels width\n",
      "Resized 'image_80.jpg' to 640 pixels width\n",
      "Resized 'image_296.jpg' to 640 pixels width\n",
      "Resized 'image_128.jpg' to 640 pixels width\n",
      "Resized 'image_394.jpg' to 640 pixels width\n",
      "Resized 'image_357.jpg' to 640 pixels width\n",
      "Resized 'image_231.jpg' to 640 pixels width\n",
      "Resized 'image_64.jpg' to 640 pixels width\n",
      "Resized 'image_353.jpg' to 640 pixels width\n",
      "Resized 'image_206.jpg' to 640 pixels width\n",
      "Resized 'image_200.jpg' to 640 pixels width\n",
      "Resized 'image_173.jpg' to 640 pixels width\n",
      "Resized 'image_55.jpg' to 640 pixels width\n",
      "Resized 'image_135.jpg' to 640 pixels width\n",
      "Resized 'image_211.jpg' to 640 pixels width\n",
      "Resized 'image_150.jpg' to 640 pixels width\n",
      "Resized 'image_163.jpg' to 640 pixels width\n",
      "Resized 'image_5.jpg' to 640 pixels width\n",
      "Resized 'image_381.jpg' to 640 pixels width\n",
      "Resized 'image_382.jpg' to 640 pixels width\n",
      "Resized 'image_218.jpg' to 640 pixels width\n",
      "Resized 'image_88.jpg' to 640 pixels width\n",
      "Resized 'image_76.jpg' to 640 pixels width\n",
      "Resized 'image_74.jpg' to 640 pixels width\n",
      "Resized 'image_188.jpg' to 640 pixels width\n",
      "Resized 'image_42.jpg' to 640 pixels width\n",
      "Resized 'image_46.jpg' to 640 pixels width\n",
      "Resized 'image_284.jpg' to 640 pixels width\n",
      "Resized 'image_32.jpg' to 640 pixels width\n",
      "Resized 'image_209.jpg' to 640 pixels width\n",
      "Resized 'image_99.jpg' to 640 pixels width\n",
      "Resized 'image_178.jpg' to 640 pixels width\n",
      "Resized 'image_215.jpg' to 640 pixels width\n",
      "Resized 'image_232.jpg' to 640 pixels width\n",
      "Resized 'image_310.jpg' to 640 pixels width\n",
      "Resized 'image_380.jpg' to 640 pixels width\n",
      "Resized 'image_387.jpg' to 640 pixels width\n",
      "Resized 'image_351.jpg' to 640 pixels width\n",
      "Resized 'image_19.jpg' to 640 pixels width\n",
      "Resized 'image_304.jpg' to 640 pixels width\n",
      "Resized 'image_193.jpg' to 640 pixels width\n",
      "Resized 'image_192.jpg' to 640 pixels width\n",
      "Resized 'image_344.jpg' to 640 pixels width\n",
      "Resized 'image_116.jpg' to 640 pixels width\n",
      "Resized 'image_203.jpg' to 640 pixels width\n",
      "Resized 'image_385.jpg' to 640 pixels width\n",
      "Resized 'image_189.jpg' to 640 pixels width\n",
      "Resized 'image_58.jpg' to 640 pixels width\n",
      "Resized 'image_369.jpg' to 640 pixels width\n",
      "Resized 'image_68.jpg' to 640 pixels width\n",
      "Resized 'image_121.jpg' to 640 pixels width\n",
      "Resized 'image_70.jpg' to 640 pixels width\n",
      "Resized 'image_262.jpg' to 640 pixels width\n",
      "Resized 'image_290.jpg' to 640 pixels width\n",
      "Resized 'image_20.jpg' to 640 pixels width\n",
      "Resized 'image_54.jpg' to 640 pixels width\n",
      "Resized 'image_389.jpg' to 640 pixels width\n",
      "Resized 'image_264.jpg' to 640 pixels width\n",
      "Resized 'image_120.jpg' to 640 pixels width\n",
      "Resized 'image_341.jpg' to 640 pixels width\n",
      "Resized 'image_355.jpg' to 640 pixels width\n",
      "Resized 'image_102.jpg' to 640 pixels width\n",
      "Resized 'image_177.jpg' to 640 pixels width\n",
      "Resized 'image_268.jpg' to 640 pixels width\n",
      "Resized 'image_249.jpg' to 640 pixels width\n",
      "Resized 'image_2.jpg' to 640 pixels width\n",
      "Resized 'image_295.jpg' to 640 pixels width\n",
      "Resized 'image_366.jpg' to 640 pixels width\n",
      "Resized 'image_38.jpg' to 640 pixels width\n",
      "Resized 'image_216.jpg' to 640 pixels width\n",
      "Resized 'image_133.jpg' to 640 pixels width\n",
      "Resized 'image_217.jpg' to 640 pixels width\n",
      "Resized 'image_18.jpg' to 640 pixels width\n",
      "Resized 'image_390.jpg' to 640 pixels width\n",
      "Resized 'image_171.jpg' to 640 pixels width\n",
      "Resized 'image_11.jpg' to 640 pixels width\n",
      "Resized 'image_376.jpg' to 640 pixels width\n",
      "Resized 'image_138.jpg' to 640 pixels width\n",
      "Resized 'image_383.jpg' to 640 pixels width\n",
      "Resized 'image_259.jpg' to 640 pixels width\n",
      "Resized 'image_396.jpg' to 640 pixels width\n",
      "Resized 'image_214.jpg' to 640 pixels width\n",
      "Resized 'image_233.jpg' to 640 pixels width\n",
      "Resized 'image_95.jpg' to 640 pixels width\n",
      "Resized 'image_122.jpg' to 640 pixels width\n",
      "Resized 'image_142.jpg' to 640 pixels width\n",
      "Resized 'image_10.jpg' to 640 pixels width\n",
      "Resized 'image_172.jpg' to 640 pixels width\n",
      "Resized 'image_226.jpg' to 640 pixels width\n",
      "Resized 'image_230.jpg' to 640 pixels width\n",
      "Resized 'image_289.jpg' to 640 pixels width\n",
      "Resized 'image_325.jpg' to 640 pixels width\n",
      "Resized 'image_371.jpg' to 640 pixels width\n",
      "Resized 'image_143.jpg' to 640 pixels width\n",
      "Resized 'image_199.jpg' to 640 pixels width\n",
      "Resized 'image_106.jpg' to 640 pixels width\n",
      "Resized 'image_367.jpg' to 640 pixels width\n",
      "Resized 'image_286.jpg' to 640 pixels width\n",
      "Resized 'image_245.jpg' to 640 pixels width\n",
      "Resized 'image_309.jpg' to 640 pixels width\n",
      "Resized 'image_155.jpg' to 640 pixels width\n",
      "Resized 'image_287.jpg' to 640 pixels width\n",
      "Resized 'image_71.jpg' to 640 pixels width\n",
      "Resized 'image_29.jpg' to 640 pixels width\n",
      "Resized 'image_308.jpg' to 640 pixels width\n",
      "Resized 'image_15.jpg' to 640 pixels width\n",
      "Resized 'image_181.jpg' to 640 pixels width\n",
      "Resized 'image_269.jpg' to 640 pixels width\n",
      "Resized 'image_272.jpg' to 640 pixels width\n",
      "Resized 'image_266.jpg' to 640 pixels width\n",
      "Resized 'image_14.jpg' to 640 pixels width\n",
      "Resized 'image_379.jpg' to 640 pixels width\n",
      "Resized 'image_164.jpg' to 640 pixels width\n",
      "Resized 'image_82.jpg' to 640 pixels width\n",
      "Resized 'image_276.jpg' to 640 pixels width\n",
      "Resized 'image_1.jpg' to 640 pixels width\n",
      "Resized 'image_375.jpg' to 640 pixels width\n",
      "Resized 'image_364.jpg' to 640 pixels width\n",
      "Resized 'image_227.jpg' to 640 pixels width\n",
      "Resized 'image_365.jpg' to 640 pixels width\n",
      "Resized 'image_179.jpg' to 640 pixels width\n",
      "Resized 'image_34.jpg' to 640 pixels width\n",
      "Resized 'image_86.jpg' to 640 pixels width\n",
      "Resized 'image_167.jpg' to 640 pixels width\n",
      "Resized 'image_125.jpg' to 640 pixels width\n",
      "Resized 'image_137.jpg' to 640 pixels width\n",
      "Resized 'image_90.jpg' to 640 pixels width\n",
      "Resized 'image_275.jpg' to 640 pixels width\n",
      "Resized 'image_220.jpg' to 640 pixels width\n",
      "Resized 'image_221.jpg' to 640 pixels width\n",
      "Resized 'image_36.jpg' to 640 pixels width\n",
      "Resized 'image_8.jpg' to 640 pixels width\n",
      "Resized 'image_320.jpg' to 640 pixels width\n",
      "Resized 'image_101.jpg' to 640 pixels width\n",
      "Resized 'image_345.jpg' to 640 pixels width\n",
      "Resized 'image_331.jpg' to 640 pixels width\n",
      "Resized 'image_23.jpg' to 640 pixels width\n",
      "Resized 'image_301.jpg' to 640 pixels width\n",
      "Resized 'image_134.jpg' to 640 pixels width\n",
      "Resized 'image_185.jpg' to 640 pixels width\n",
      "Resized 'image_263.jpg' to 640 pixels width\n",
      "Resized 'image_157.jpg' to 640 pixels width\n",
      "Resized 'image_41.jpg' to 640 pixels width\n",
      "Resized 'image_43.jpg' to 640 pixels width\n",
      "Resized 'image_267.jpg' to 640 pixels width\n",
      "Resized 'image_35.jpg' to 640 pixels width\n",
      "Resized 'image_136.jpg' to 640 pixels width\n",
      "Resized 'image_39.jpg' to 640 pixels width\n",
      "Resized 'image_243.jpg' to 640 pixels width\n",
      "Resized 'image_191.jpg' to 640 pixels width\n",
      "Resized 'image_117.jpg' to 640 pixels width\n",
      "Resized 'image_237.jpg' to 640 pixels width\n",
      "Resized 'image_281.jpg' to 640 pixels width\n",
      "Resized 'image_112.jpg' to 640 pixels width\n",
      "Resized 'image_340.jpg' to 640 pixels width\n",
      "Resized 'image_384.jpg' to 640 pixels width\n",
      "Resized 'image_129.jpg' to 640 pixels width\n",
      "Resized 'image_242.jpg' to 640 pixels width\n",
      "Resized 'image_270.jpg' to 640 pixels width\n",
      "Resized 'image_103.jpg' to 640 pixels width\n",
      "Resized 'image_184.jpg' to 640 pixels width\n",
      "Resized 'image_149.jpg' to 640 pixels width\n",
      "Resized 'image_280.jpg' to 640 pixels width\n",
      "Resized 'image_194.jpg' to 640 pixels width\n",
      "Resized 'image_7.jpg' to 640 pixels width\n",
      "Resized 'image_248.jpg' to 640 pixels width\n",
      "Resized 'image_297.jpg' to 640 pixels width\n",
      "Resized 'image_260.jpg' to 640 pixels width\n",
      "Resized 'image_300.jpg' to 640 pixels width\n",
      "Resized 'image_252.jpg' to 640 pixels width\n",
      "Resized 'image_12.jpg' to 640 pixels width\n",
      "Resized 'image_61.jpg' to 640 pixels width\n",
      "Resized 'image_274.jpg' to 640 pixels width\n",
      "Resized 'image_81.jpg' to 640 pixels width\n",
      "Resized 'image_356.jpg' to 640 pixels width\n",
      "Resized 'image_6.jpg' to 640 pixels width\n",
      "Resized 'image_348.jpg' to 640 pixels width\n",
      "Resized 'image_110.jpg' to 640 pixels width\n",
      "Resized 'image_28.jpg' to 640 pixels width\n",
      "Resized 'image_158.jpg' to 640 pixels width\n",
      "Resized 'image_198.jpg' to 640 pixels width\n",
      "Resized 'image_59.jpg' to 640 pixels width\n",
      "Resized 'image_72.jpg' to 640 pixels width\n",
      "Resized 'image_168.jpg' to 640 pixels width\n",
      "Resized 'image_208.jpg' to 640 pixels width\n",
      "Resized 'image_282.jpg' to 640 pixels width\n",
      "Resized 'image_235.jpg' to 640 pixels width\n",
      "Resized 'image_13.jpg' to 640 pixels width\n",
      "Resized 'image_115.jpg' to 640 pixels width\n",
      "Resized 'image_113.jpg' to 640 pixels width\n",
      "Resized 'image_159.jpg' to 640 pixels width\n",
      "Resized 'image_337.jpg' to 640 pixels width\n",
      "Resized 'image_279.jpg' to 640 pixels width\n",
      "Resized 'image_229.jpg' to 640 pixels width\n",
      "Resized 'image_256.jpg' to 640 pixels width\n",
      "Resized 'image_97.jpg' to 640 pixels width\n",
      "Resized 'image_219.jpg' to 640 pixels width\n",
      "Resized 'image_240.jpg' to 640 pixels width\n",
      "Resized 'image_323.jpg' to 640 pixels width\n",
      "Resized 'image_17.jpg' to 640 pixels width\n",
      "Resized 'image_187.jpg' to 640 pixels width\n",
      "Resized 'image_332.jpg' to 640 pixels width\n",
      "Resized 'image_89.jpg' to 640 pixels width\n",
      "Resized 'image_147.jpg' to 640 pixels width\n",
      "Resized 'image_111.jpg' to 640 pixels width\n",
      "Resized 'image_377.jpg' to 640 pixels width\n",
      "Resized 'image_69.jpg' to 640 pixels width\n",
      "Resized 'image_271.jpg' to 640 pixels width\n",
      "Resized 'image_378.jpg' to 640 pixels width\n",
      "Resized 'image_228.jpg' to 640 pixels width\n",
      "Resized 'image_9.jpg' to 640 pixels width\n",
      "Resized 'image_98.jpg' to 640 pixels width\n",
      "Resized 'image_212.jpg' to 640 pixels width\n",
      "Resized 'image_62.jpg' to 640 pixels width\n",
      "Resized 'image_303.jpg' to 640 pixels width\n",
      "Resized 'image_393.jpg' to 640 pixels width\n",
      "Resized 'image_239.jpg' to 640 pixels width\n",
      "Resized 'image_316.jpg' to 640 pixels width\n",
      "Resized 'image_391.jpg' to 640 pixels width\n",
      "Resized 'image_315.jpg' to 640 pixels width\n",
      "Resized 'image_22.jpg' to 640 pixels width\n",
      "Resized 'image_336.jpg' to 640 pixels width\n",
      "Resized 'image_31.jpg' to 640 pixels width\n",
      "Resized 'image_254.jpg' to 640 pixels width\n",
      "Resized 'image_37.jpg' to 640 pixels width\n",
      "Resized 'image_124.jpg' to 640 pixels width\n",
      "Resized 'image_50.jpg' to 640 pixels width\n",
      "Resized 'image_210.jpg' to 640 pixels width\n",
      "Resized 'image_224.jpg' to 640 pixels width\n",
      "Resized 'image_319.jpg' to 640 pixels width\n",
      "Resized 'image_334.jpg' to 640 pixels width\n",
      "Resized 'image_236.jpg' to 640 pixels width\n",
      "Resized 'image_339.jpg' to 640 pixels width\n",
      "Resized 'image_3.jpg' to 640 pixels width\n",
      "Resized 'image_225.jpg' to 640 pixels width\n",
      "Resized 'image_40.jpg' to 640 pixels width\n",
      "Resized 'image_251.jpg' to 640 pixels width\n",
      "Resized 'image_238.jpg' to 640 pixels width\n",
      "Resized 'image_370.jpg' to 640 pixels width\n",
      "Resized 'image_27.jpg' to 640 pixels width\n",
      "Resized 'image_313.jpg' to 640 pixels width\n",
      "Resized 'image_140.jpg' to 640 pixels width\n",
      "Resized 'image_234.jpg' to 640 pixels width\n",
      "Resized 'image_317.jpg' to 640 pixels width\n",
      "Resized 'image_130.jpg' to 640 pixels width\n",
      "Resized 'image_312.jpg' to 640 pixels width\n",
      "Resized 'image_291.jpg' to 640 pixels width\n",
      "Resized 'image_21.jpg' to 640 pixels width\n",
      "Resized 'image_314.jpg' to 640 pixels width\n",
      "Resized 'image_0.jpg' to 640 pixels width\n",
      "Resized 'image_213.jpg' to 640 pixels width\n",
      "Resized 'image_361.jpg' to 640 pixels width\n",
      "Resized 'image_182.jpg' to 640 pixels width\n",
      "Resized 'image_156.jpg' to 640 pixels width\n",
      "Resized 'image_258.jpg' to 640 pixels width\n",
      "Resized 'image_342.jpg' to 640 pixels width\n",
      "Resized 'image_195.jpg' to 640 pixels width\n",
      "Resized 'image_186.jpg' to 640 pixels width\n",
      "Resized 'image_25.jpg' to 640 pixels width\n",
      "Resized 'image_283.jpg' to 640 pixels width\n",
      "Resized 'image_347.jpg' to 640 pixels width\n",
      "Resized 'image_368.jpg' to 640 pixels width\n",
      "Resized 'image_190.jpg' to 640 pixels width\n",
      "Resized 'image_277.jpg' to 640 pixels width\n",
      "Resized 'image_293.jpg' to 640 pixels width\n",
      "Resized 'image_165.jpg' to 640 pixels width\n",
      "Resized 'image_373.jpg' to 640 pixels width\n"
     ]
    }
   ],
   "source": [
    "# just in case, we re-size all images to 640 pixels\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set the path to the directory containing your images\n",
    "image_dir = '../data/transfer_learning/'\n",
    "\n",
    "# Set the target width for resizing\n",
    "target_width = 640\n",
    "\n",
    "# Iterate over each image in the directory\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "     for filename in files:\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Open the image file\n",
    "            image_path = os.path.join(root, filename)\n",
    "            img = Image.open(image_path)\n",
    "            \n",
    "            # Calculate the proportional height based on the target width\n",
    "            width, height = img.size\n",
    "            target_height = int((height / width) * target_width)\n",
    "            \n",
    "            # Resize the image using the target width and proportional height\n",
    "            resized_img = img.resize((target_width, target_height))\n",
    "            \n",
    "            # Save the resized image, overwriting the original file\n",
    "            resized_img.save(image_path)\n",
    "\n",
    "            print(f\"Resized '{filename}' to {target_width} pixels width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794\n"
     ]
    }
   ],
   "source": [
    "%ls -1 ../data/annotated/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = ['train', 'val', 'test']\n",
    "total_count = 794/2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a tunning - we used only 1 image for validation placeholder. We want more training images because we only have 400 images. Also note that yolo5s-CXR.yaml actually uses yolo5x - same architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of images in train: 0.7531486146095718\n",
      "% of images in val: 0.0025188916876574307\n",
      "% of images in test: 0.24433249370277077\n"
     ]
    }
   ],
   "source": [
    "for p in prefix:\n",
    "    all_images = []\n",
    "    image_dir = f'../data/transfer_learning/{p}/'\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'): \n",
    "            all_images.append(filename)\n",
    "    print(f\"% of images in {p}: {len(all_images)/total_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up reference before training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done in an editor:\n",
    "\n",
    "- create new data yaml files (train, val reference) -> data/CXR.yaml\n",
    "- update the yolov5x.ymal regarding the class numbers  -> models/yolov5s-CXR.yaml\n",
    "- duplicate yolov5n.pt and yolov5s.pt to the /weights folder -> weights/yolov5s-CXR.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/home/zle2435/dl_proj/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd ../yolov5/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning \n",
    "with only architecture (not freezing any layers) and no agumentation (based on the yaml file) - the full architecture can be found at [ultralytics](https://docs.ultralytics.com/yolov5/tutorials/architecture_description/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=./models/yolov5s-CXR.yaml, data=./data/CXR.yaml, hyp=data/hyps/hyp.no-augmentation.yaml, epochs=32, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0,1,2,3, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "remote: Enumerating objects: 230, done.\u001b[K\n",
      "remote: Counting objects: 100% (194/194), done.\u001b[K\n",
      "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
      "remote: Total 230 (delta 165), reused 176 (delta 154), pack-reused 36\u001b[K\n",
      "Receiving objects: 100% (230/230), 75.77 KiB | 5.41 MiB/s, done.\n",
      "Resolving deltas: 100% (183/183), completed with 25 local objects.\n",
      "From https://github.com/ultralytics/yolov5\n",
      "   c3c1304..5f11555  master              -> origin/master\n",
      "   ec19741..96dbd7c  snyk-fix-09d8acaff69195c641ab1e77119e4c6b -> origin/snyk-fix-09d8acaff69195c641ab1e77119e4c6b\n",
      " * [new branch]      ultralytics_cleanup -> origin/ultralytics_cleanup\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 7 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "YOLOv5 üöÄ v7.0-168-gec2b853 Python-3.10.6 torch-2.0.1+cu117 CUDA:0 (NVIDIA RTX A6000, 48685MiB)\n",
      "                                                            CUDA:1 (NVIDIA RTX A6000, 48685MiB)\n",
      "                                                            CUDA:2 (NVIDIA RTX A6000, 48685MiB)\n",
      "                                                            CUDA:3 (NVIDIA RTX A6000, 48685MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0.0, translate=0, scale=0, shear=0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
      "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
      "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
      "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
      "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
      "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
      "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
      " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
      " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
      " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
      " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
      " 24      [17, 20, 23]  1     40374  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
      "YOLOv5s-CXR summary: 445 layers, 86217814 parameters, 86217814 gradients, 204.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
      "WARNING ‚ö†Ô∏è DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n",
      "See Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/train.ca\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/train/image_266.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1859      1.0814]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/val.cache.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.41 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to runs/train/exp8/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp8\u001b[0m\n",
      "Starting training for 32 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/31      7.22G       0.11    0.01763          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1    0.00333          1    0.00336    0.00101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/31      7.25G       0.11    0.01761          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1    0.00333          1    0.00578    0.00174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/31      7.25G     0.1089    0.01757          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1    0.00333          1    0.00578    0.00174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/31      7.25G     0.1076    0.01754          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1    0.00333          1    0.00565     0.0017\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/31      7.25G     0.1077    0.01736          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1    0.00333          1    0.00556    0.00167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/31      8.04G     0.1066    0.01728          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1    0.00333          1     0.0061    0.00183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/31      8.04G     0.1063    0.01714          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1    0.00333          1    0.00363    0.00109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/31      8.04G     0.1061    0.01708          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1    0.00333          1    0.00459    0.00183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/31      8.04G     0.1041    0.01708          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1    0.00333          1    0.00526    0.00211\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/31      8.04G      0.102    0.01701          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1    0.00333          1    0.00345    0.00173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/31      8.04G    0.09968    0.01693          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/31      8.04G    0.09702     0.0166          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/31      8.04G    0.09366    0.01597          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/31      8.04G    0.08911    0.01529          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/31      8.04G    0.08665    0.01453          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/31      8.04G    0.08504    0.01366          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/31      8.04G    0.08359    0.01301          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/31      8.04G    0.08288    0.01262          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/31      8.04G    0.08216    0.01221          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1    0.00333          1     0.0355     0.0178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/31      8.04G    0.08201    0.01197          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/31      8.04G    0.08095    0.01184          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/31      8.04G    0.07984     0.0117          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/31      8.04G    0.07902    0.01165          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/31      8.04G    0.07947    0.01147          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/31      8.04G    0.07861    0.01142          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/31      8.04G    0.07737    0.01146          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/31      8.04G    0.07627    0.01151          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/31      8.04G     0.0765    0.01141          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/31      8.04G    0.07605    0.01129          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/31      8.04G    0.07402    0.01158          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/31      8.04G     0.0743    0.01146          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/31      8.04G    0.07368    0.01151          0         10        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1          0          0          0          0\n",
      "\n",
      "32 epochs completed in 0.109 hours.\n",
      "Optimizer stripped from runs/train/exp8/weights/last.pt, 173.1MB\n",
      "Optimizer stripped from runs/train/exp8/weights/best.pt, 173.1MB\n",
      "\n",
      "Validating runs/train/exp8/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5s-CXR summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          1    0.00333          1     0.0311     0.0155\n",
      "Results saved to \u001b[1mruns/train/exp8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# train yolov5s on custom data for 1 epochs\n",
    "!python3 train.py --weights '' --hyp data/hyps/hyp.no-augmentation.yaml --cfg ./models/yolov5x-CXR.yaml --img 640 --epochs 32 --batch 32 --data ./data/CXR.yaml --device 0,1,2,3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference \n",
    "with test data and check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp8/weights/best.pt'], source=data/transfer_learning/test/, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.0001, iou_thres=0.0001, max_det=1, device=0,1,2,3, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=True, half=False, dnn=False, vid_stride=1\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /nfs/home/zle2435/dl_proj/.venv/lib/python3.10/site-packages/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-168-gec2b853 Python-3.10.6 torch-2.0.1+cu117 CUDA:0 (NVIDIA RTX A6000, 48685MiB)\n",
      "                                                            CUDA:1 (NVIDIA RTX A6000, 48685MiB)\n",
      "                                                            CUDA:2 (NVIDIA RTX A6000, 48685MiB)\n",
      "                                                            CUDA:3 (NVIDIA RTX A6000, 48685MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-CXR summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n",
      "image 1/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_100.jpg: 640x544 1 foreign_object, 68.1ms\n",
      "image 2/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_105.jpg: 640x544 1 foreign_object, 14.0ms\n",
      "image 3/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_107.jpg: 640x640 1 foreign_object, 15.3ms\n",
      "image 4/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_108.jpg: 640x640 1 foreign_object, 13.8ms\n",
      "image 5/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_109.jpg: 640x640 1 foreign_object, 13.9ms\n",
      "image 6/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_114.jpg: 544x640 1 foreign_object, 71.7ms\n",
      "image 7/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_118.jpg: 640x448 1 foreign_object, 70.9ms\n",
      "image 8/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_119.jpg: 640x576 1 foreign_object, 69.8ms\n",
      "image 9/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_126.jpg: 640x640 1 foreign_object, 15.2ms\n",
      "image 10/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_128.jpg: 640x480 1 foreign_object, 73.3ms\n",
      "image 11/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_135.jpg: 544x640 1 foreign_object, 14.6ms\n",
      "image 12/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_144.jpg: 544x640 1 foreign_object, 14.2ms\n",
      "image 13/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_145.jpg: 640x544 1 foreign_object, 14.5ms\n",
      "image 14/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_146.jpg: 608x640 1 foreign_object, 69.4ms\n",
      "image 15/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_150.jpg: 640x544 1 foreign_object, 14.6ms\n",
      "image 16/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_151.jpg: 640x640 1 foreign_object, 14.7ms\n",
      "image 17/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_16.jpg: 640x512 1 foreign_object, 76.2ms\n",
      "image 18/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_162.jpg: 640x576 1 foreign_object, 14.6ms\n",
      "image 19/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_163.jpg: 640x640 1 foreign_object, 15.2ms\n",
      "image 20/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_170.jpg: 640x544 1 foreign_object, 15.1ms\n",
      "image 21/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_173.jpg: 640x640 1 foreign_object, 14.3ms\n",
      "image 22/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_175.jpg: 640x544 1 foreign_object, 14.8ms\n",
      "image 23/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_176.jpg: 640x576 1 foreign_object, 14.8ms\n",
      "image 24/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_180.jpg: 640x512 1 foreign_object, 14.7ms\n",
      "image 25/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_188.jpg: 640x640 1 foreign_object, 14.7ms\n",
      "image 26/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_200.jpg: 544x640 1 foreign_object, 14.5ms\n",
      "image 27/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_202.jpg: 640x640 1 foreign_object, 14.6ms\n",
      "image 28/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_206.jpg: 640x544 1 foreign_object, 14.8ms\n",
      "image 29/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_207.jpg: 640x544 1 foreign_object, 14.3ms\n",
      "image 30/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_211.jpg: 640x544 1 foreign_object, 14.6ms\n",
      "image 31/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_218.jpg: 640x640 1 foreign_object, 14.6ms\n",
      "image 32/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_222.jpg: 640x640 1 foreign_object, 14.0ms\n",
      "image 33/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_223.jpg: 608x640 1 foreign_object, 14.3ms\n",
      "image 34/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_231.jpg: 640x544 1 foreign_object, 15.2ms\n",
      "image 35/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_246.jpg: 640x576 1 foreign_object, 14.5ms\n",
      "image 36/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_247.jpg: 640x544 1 foreign_object, 15.1ms\n",
      "image 37/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_250.jpg: 640x640 1 foreign_object, 14.6ms\n",
      "image 38/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_253.jpg: 640x576 1 foreign_object, 14.4ms\n",
      "image 39/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_26.jpg: 640x512 1 foreign_object, 14.7ms\n",
      "image 40/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_261.jpg: 640x544 1 foreign_object, 14.7ms\n",
      "image 41/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_273.jpg: 640x640 1 foreign_object, 14.6ms\n",
      "image 42/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_278.jpg: 640x544 1 foreign_object, 14.8ms\n",
      "image 43/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_288.jpg: 640x544 1 foreign_object, 14.2ms\n",
      "image 44/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_292.jpg: 640x640 1 foreign_object, 14.7ms\n",
      "image 45/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_294.jpg: 640x544 1 foreign_object, 14.5ms\n",
      "image 46/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_296.jpg: 640x544 1 foreign_object, 14.3ms\n",
      "image 47/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_298.jpg: 640x544 1 foreign_object, 14.3ms\n",
      "image 48/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_299.jpg: 640x640 1 foreign_object, 16.2ms\n",
      "image 49/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_30.jpg: 640x640 1 foreign_object, 14.0ms\n",
      "image 50/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_305.jpg: 640x544 1 foreign_object, 15.3ms\n",
      "image 51/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_306.jpg: 640x640 1 foreign_object, 14.4ms\n",
      "image 52/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_318.jpg: 640x544 1 foreign_object, 14.4ms\n",
      "image 53/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_322.jpg: 608x640 1 foreign_object, 15.3ms\n",
      "image 54/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_327.jpg: 640x640 1 foreign_object, 14.6ms\n",
      "image 55/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_328.jpg: 640x640 1 foreign_object, 14.4ms\n",
      "image 56/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_338.jpg: 640x544 1 foreign_object, 14.4ms\n",
      "image 57/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_343.jpg: 640x576 1 foreign_object, 14.8ms\n",
      "image 58/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_346.jpg: 544x640 1 foreign_object, 14.3ms\n",
      "image 59/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_350.jpg: 640x544 1 foreign_object, 15.3ms\n",
      "image 60/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_353.jpg: 544x640 1 foreign_object, 14.3ms\n",
      "image 61/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_354.jpg: 608x640 1 foreign_object, 14.5ms\n",
      "image 62/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_357.jpg: 640x640 1 foreign_object, 15.4ms\n",
      "image 63/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_358.jpg: 640x640 1 foreign_object, 13.8ms\n",
      "image 64/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_359.jpg: 640x640 1 foreign_object, 13.8ms\n",
      "image 65/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_360.jpg: 640x544 1 foreign_object, 14.4ms\n",
      "image 66/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_372.jpg: 544x640 1 foreign_object, 15.3ms\n",
      "image 67/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_374.jpg: 640x544 1 foreign_object, 14.7ms\n",
      "image 68/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_381.jpg: 640x544 1 foreign_object, 14.8ms\n",
      "image 69/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_382.jpg: 640x544 1 foreign_object, 14.0ms\n",
      "image 70/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_388.jpg: 544x640 1 foreign_object, 14.9ms\n",
      "image 71/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_392.jpg: 640x640 1 foreign_object, 14.6ms\n",
      "image 72/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_394.jpg: 640x544 1 foreign_object, 14.6ms\n",
      "image 73/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_399.jpg: 544x640 1 foreign_object, 14.3ms\n",
      "image 74/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_4.jpg: 640x544 1 foreign_object, 15.1ms\n",
      "image 75/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_42.jpg: 640x544 1 foreign_object, 14.0ms\n",
      "image 76/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_46.jpg: 640x640 1 foreign_object, 14.5ms\n",
      "image 77/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_5.jpg: 640x544 1 foreign_object, 15.4ms\n",
      "image 78/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_51.jpg: 640x640 1 foreign_object, 14.5ms\n",
      "image 79/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_52.jpg: 640x576 1 foreign_object, 15.3ms\n",
      "image 80/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_53.jpg: 640x576 1 foreign_object, 14.3ms\n",
      "image 81/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_55.jpg: 640x544 1 foreign_object, 15.6ms\n",
      "image 82/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_56.jpg: 640x640 1 foreign_object, 14.5ms\n",
      "image 83/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_60.jpg: 640x544 1 foreign_object, 14.7ms\n",
      "image 84/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_64.jpg: 544x640 1 foreign_object, 15.0ms\n",
      "image 85/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_74.jpg: 640x640 1 foreign_object, 14.6ms\n",
      "image 86/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_75.jpg: 640x640 1 foreign_object, 14.3ms\n",
      "image 87/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_76.jpg: 640x544 1 foreign_object, 14.8ms\n",
      "image 88/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_77.jpg: 640x640 1 foreign_object, 15.5ms\n",
      "image 89/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_78.jpg: 640x640 1 foreign_object, 14.2ms\n",
      "image 90/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_79.jpg: 640x544 1 foreign_object, 16.2ms\n",
      "image 91/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_80.jpg: 640x640 1 foreign_object, 14.5ms\n",
      "image 92/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_83.jpg: 640x544 1 foreign_object, 14.5ms\n",
      "image 93/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_84.jpg: 608x640 1 foreign_object, 15.4ms\n",
      "image 94/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_87.jpg: 640x512 1 foreign_object, 15.4ms\n",
      "image 95/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_88.jpg: 640x640 1 foreign_object, 14.7ms\n",
      "image 96/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_94.jpg: 640x544 1 foreign_object, 14.6ms\n",
      "image 97/97 /nfs/home/zle2435/dl_proj/yolov5/data/transfer_learning/test/image_96.jpg: 640x608 1 foreign_object, 70.3ms\n",
      "Speed: 0.5ms pre-process, 19.3ms inference, 48.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp28\u001b[0m\n",
      "97 labels saved to runs/detect/exp28/labels\n"
     ]
    }
   ],
   "source": [
    "!python3 detect.py --source data/transfer_learning/test/ --weights runs/train/exp8/weights/best.pt --img 640 --save-txt --device 0,1,2,3 --conf-thres 0.0001 --iou-thres 0.0001 --max-det 1 --hide-conf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can now be found at the `runs/detect/{exp_index}`. Let's test a pair of box coordinates (x, y, w, h) and calculate the iou from the test folder - we are checking prediction against groud truth of course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import bbox_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/home/zle2435/dl_proj/yolov5'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord(dir:str, file_name:str) -> torch.Tensor:\n",
    "    \"\"\"from a .txt file, read the first line, and get the (x,y,w,h) coordinates\"\"\"\n",
    "    with open(dir + file_name, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        box_coords = [float(coord) for coord in lines[0].split()[1:]] # first elem is class\n",
    "    return torch.Tensor(box_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box 1: tensor([0.2218, 0.1087, 0.0355, 0.0378])\n",
      "Box 2: tensor([0.9812, 0.0701, 0.0375, 0.1041])\n",
      "IoU: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "ground_truth_dir = r'../data/transfer_learning/test/'\n",
    "prediction_dir = r'runs/detect/exp28/labels/'\n",
    "file_name = 'image_4.txt'\n",
    "\n",
    "box1 = get_coord(ground_truth_dir, file_name)\n",
    "box2 = get_coord(prediction_dir, file_name)\n",
    "iou = bbox_iou(box1, box2)\n",
    "\n",
    "print(\"Box 1:\", box1)\n",
    "print(\"Box 2:\", box2)\n",
    "print(\"IoU:\", iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for image_107, groud truth:tensor([0.4886, 0.8776, 0.5742, 0.1491]), pred:tensor([0.8375, 0.7684, 0.0688, 0.0970]), IoU is 0.0\n",
      "for image_108, groud truth:tensor([0.4948, 0.5658, 0.7181, 0.3464]), pred:tensor([0.9516, 0.0493, 0.0969, 0.0986]), IoU is 0.0\n",
      "for image_144, groud truth:tensor([0.5184, 0.1011, 0.4176, 0.1904]), pred:tensor([0.1594, 0.7943, 0.3187, 0.4114]), IoU is 0.0\n",
      "for image_327, groud truth:tensor([0.3374, 0.0788, 0.3499, 0.1159]), pred:tensor([0.3039, 0.1179, 0.0734, 0.1066]), IoU is 0.1229923814535141\n",
      "for image_126, groud truth:tensor([0.4378, 0.5866, 0.1061, 0.0918]), pred:tensor([0.9500, 0.9476, 0.1000, 0.1049]), IoU is 0.0\n",
      "for image_162, groud truth:tensor([0.4884, 0.0718, 0.0824, 0.1260]), pred:tensor([0.8773, 0.0442, 0.0453, 0.0885]), IoU is 0.0\n",
      "for image_151, groud truth:tensor([0.7812, 0.6193, 0.0658, 0.1292]), pred:tensor([0.8797, 0.9491, 0.1031, 0.1019]), IoU is 0.0\n",
      "for image_64, groud truth:tensor([0.6377, 0.5913, 0.2643, 0.1631]), pred:tensor([0.0477, 0.7457, 0.0953, 0.1747]), IoU is 0.0\n",
      "for image_42, groud truth:tensor([0.3594, 0.1265, 0.1582, 0.1240]), pred:tensor([0.9461, 0.0495, 0.1078, 0.0990]), IoU is 0.0\n",
      "for image_222, groud truth:tensor([0.4582, 0.6387, 0.3219, 0.2220]), pred:tensor([0.9609, 0.9700, 0.0656, 0.0601]), IoU is 0.0\n",
      "for image_354, groud truth:tensor([0.6359, 0.4440, 0.0732, 0.0501]), pred:tensor([0.9563, 0.0786, 0.0875, 0.1474]), IoU is 0.0\n",
      "for image_231, groud truth:tensor([0.2173, 0.3239, 0.2191, 0.1628]), pred:tensor([0.9461, 0.0495, 0.1078, 0.0990]), IoU is 0.0\n",
      "for image_188, groud truth:tensor([0.5120, 0.0526, 0.4798, 0.0973]), pred:tensor([0.8695, 0.2297, 0.1078, 0.2062]), IoU is 0.0\n",
      "for image_94, groud truth:tensor([0.3913, 0.3271, 0.5905, 0.3210]), pred:tensor([0.9461, 0.0495, 0.1078, 0.0990]), IoU is 0.0\n",
      "for image_52, groud truth:tensor([0.3009, 0.1849, 0.0609, 0.0488]), pred:tensor([0.0672, 0.9184, 0.0656, 0.0907]), IoU is 0.0\n",
      "for image_372, groud truth:tensor([0.2746, 0.1737, 0.0635, 0.0771]), pred:tensor([0.9516, 0.0506, 0.0969, 0.1011]), IoU is 0.0\n",
      "for image_343, groud truth:tensor([0.5301, 0.1032, 0.1520, 0.1777]), pred:tensor([0.9539, 0.9487, 0.0922, 0.1026]), IoU is 0.0\n",
      "for image_30, groud truth:tensor([0.5106, 0.5845, 0.1995, 0.2308]), pred:tensor([0.9563, 0.0495, 0.0875, 0.0991]), IoU is 0.0\n",
      "for image_75, groud truth:tensor([0.4834, 0.3008, 0.2253, 0.5658]), pred:tensor([0.9531, 0.0490, 0.0938, 0.0980]), IoU is 0.0\n",
      "for image_175, groud truth:tensor([0.3206, 0.3971, 0.0794, 0.0964]), pred:tensor([0.6664, 0.1799, 0.2109, 0.2510]), IoU is 0.0\n",
      "for image_114, groud truth:tensor([0.1255, 0.3504, 0.0817, 0.2633]), pred:tensor([0.0867, 0.9198, 0.0703, 0.1107]), IoU is 0.0\n",
      "for image_261, groud truth:tensor([0.1501, 0.6947, 0.0964, 0.2728]), pred:tensor([0.0656, 0.8203, 0.0781, 0.0911]), IoU is 0.004741838667541742\n",
      "for image_96, groud truth:tensor([0.3138, 0.6343, 0.4290, 0.2145]), pred:tensor([0.9586, 0.0490, 0.0828, 0.0980]), IoU is 0.0\n",
      "for image_55, groud truth:tensor([0.2702, 0.1131, 0.1003, 0.1956]), pred:tensor([0.2109, 0.8327, 0.4219, 0.3346]), IoU is 0.0\n",
      "for image_273, groud truth:tensor([0.5273, 0.1766, 0.3333, 0.2705]), pred:tensor([0.9531, 0.7782, 0.0938, 0.1364]), IoU is 0.0\n",
      "for image_78, groud truth:tensor([0.6016, 0.5298, 0.1543, 0.1566]), pred:tensor([0.6805, 0.0867, 0.0984, 0.1734]), IoU is 0.0\n",
      "for image_119, groud truth:tensor([0.2868, 0.0879, 0.1185, 0.1445]), pred:tensor([0.9547, 0.0493, 0.0906, 0.0985]), IoU is 0.0\n",
      "for image_223, groud truth:tensor([0.2681, 0.0381, 0.0596, 0.0664]), pred:tensor([0.0461, 0.8742, 0.0922, 0.1583]), IoU is 0.0\n",
      "for image_318, groud truth:tensor([0.4886, 0.1995, 0.1068, 0.0807]), pred:tensor([0.9461, 0.0495, 0.1078, 0.0990]), IoU is 0.0\n",
      "for image_88, groud truth:tensor([0.5207, 0.5000, 0.0719, 0.1003]), pred:tensor([0.2367, 0.1680, 0.0641, 0.0953]), IoU is 0.0\n",
      "for image_206, groud truth:tensor([0.2484, 0.1826, 0.1003, 0.1562]), pred:tensor([0.2445, 0.2192, 0.4891, 0.4383]), IoU is 0.0730820745229721\n",
      "for image_53, groud truth:tensor([0.5632, 0.0778, 0.0781, 0.0898]), pred:tensor([0.9563, 0.0496, 0.0875, 0.0992]), IoU is 0.0\n",
      "for image_299, groud truth:tensor([0.0999, 0.7982, 0.0605, 0.3210]), pred:tensor([0.3336, 0.1717, 0.1922, 0.1094]), IoU is 0.0\n",
      "for image_358, groud truth:tensor([0.4767, 0.6250, 0.2249, 0.2643]), pred:tensor([0.9617, 0.0491, 0.0766, 0.0982]), IoU is 0.0\n",
      "for image_338, groud truth:tensor([0.2645, 0.4647, 0.0798, 0.1423]), pred:tensor([0.9508, 0.0495, 0.0984, 0.0990]), IoU is 0.0\n",
      "for image_394, groud truth:tensor([0.4575, 0.1154, 0.0713, 0.1006]), pred:tensor([0.8117, 0.1288, 0.1109, 0.1628]), IoU is 0.0\n",
      "for image_253, groud truth:tensor([0.2734, 0.5933, 0.1621, 0.1520]), pred:tensor([0.9586, 0.0772, 0.0828, 0.1409]), IoU is 0.0\n",
      "for image_76, groud truth:tensor([0.3667, 0.6240, 0.2516, 0.1849]), pred:tensor([0.0484, 0.0442, 0.0969, 0.0883]), IoU is 0.0\n",
      "for image_146, groud truth:tensor([0.4788, 0.7861, 0.2331, 0.1484]), pred:tensor([0.9516, 0.0465, 0.0969, 0.0929]), IoU is 0.0\n",
      "for image_296, groud truth:tensor([0.4372, 0.0871, 0.4342, 0.1370]), pred:tensor([0.9461, 0.0495, 0.1078, 0.0990]), IoU is 0.0\n",
      "for image_46, groud truth:tensor([0.4002, 0.0854, 0.3519, 0.1507]), pred:tensor([0.0477, 0.6281, 0.0953, 0.1525]), IoU is 0.0\n",
      "for image_306, groud truth:tensor([0.3203, 0.1400, 0.1016, 0.0781]), pred:tensor([0.2367, 0.1307, 0.2391, 0.0861]), IoU is 0.28438815474510193\n",
      "for image_105, groud truth:tensor([0.2751, 0.4691, 0.1022, 0.0983]), pred:tensor([0.8172, 0.0431, 0.0312, 0.0553]), IoU is 0.0\n",
      "for image_100, groud truth:tensor([0.3851, 0.3538, 0.3477, 0.0951]), pred:tensor([0.8484, 0.0431, 0.0344, 0.0681]), IoU is 0.0\n",
      "for image_353, groud truth:tensor([0.2603, 0.3345, 0.2028, 0.4678]), pred:tensor([0.9508, 0.0506, 0.0984, 0.1011]), IoU is 0.0\n",
      "for image_288, groud truth:tensor([0.3226, 0.5433, 0.0605, 0.0905]), pred:tensor([0.6687, 0.8798, 0.1656, 0.2224]), IoU is 0.0\n",
      "for image_83, groud truth:tensor([0.3706, 0.4686, 0.2835, 0.2451]), pred:tensor([0.9523, 0.6311, 0.0953, 0.1465]), IoU is 0.0\n",
      "for image_87, groud truth:tensor([0.3351, 0.3695, 0.0563, 0.0990]), pred:tensor([0.9438, 0.0494, 0.1125, 0.0988]), IoU is 0.0\n",
      "for image_392, groud truth:tensor([0.4686, 0.0643, 0.0999, 0.1214]), pred:tensor([0.9516, 0.0447, 0.0969, 0.0893]), IoU is 0.0\n",
      "for image_60, groud truth:tensor([0.2848, 0.2052, 0.2721, 0.2354]), pred:tensor([0.9328, 0.4197, 0.1344, 0.1684]), IoU is 0.0\n",
      "for image_176, groud truth:tensor([0.4193, 0.1296, 0.3105, 0.1999]), pred:tensor([0.9828, 0.6236, 0.0344, 0.1060]), IoU is 0.0\n",
      "for image_218, groud truth:tensor([0.6196, 0.1375, 0.0928, 0.1481]), pred:tensor([0.9594, 0.0496, 0.0812, 0.0992]), IoU is 0.0\n",
      "for image_173, groud truth:tensor([0.5334, 0.4468, 0.0889, 0.1540]), pred:tensor([0.9523, 0.0492, 0.0953, 0.0984]), IoU is 0.0\n",
      "for image_207, groud truth:tensor([0.3901, 0.3428, 0.0999, 0.2982]), pred:tensor([0.6062, 0.1808, 0.2094, 0.2389]), IoU is 0.0\n",
      "for image_79, groud truth:tensor([0.5695, 0.5252, 0.1501, 0.2380]), pred:tensor([0.9547, 0.9490, 0.0906, 0.1019]), IoU is 0.0\n",
      "for image_305, groud truth:tensor([0.4492, 0.6481, 0.6693, 0.2936]), pred:tensor([0.3172, 0.1046, 0.5312, 0.2091]), IoU is 0.0\n",
      "for image_170, groud truth:tensor([0.2645, 0.1364, 0.2529, 0.2383]), pred:tensor([0.6109, 0.1806, 0.2000, 0.2481]), IoU is 0.0\n",
      "for image_16, groud truth:tensor([0.3615, 0.1745, 0.4307, 0.2858]), pred:tensor([0.9484, 0.0490, 0.1031, 0.0981]), IoU is 0.0\n",
      "for image_292, groud truth:tensor([0.4771, 0.2417, 0.1292, 0.3369]), pred:tensor([0.9516, 0.9484, 0.0969, 0.1031]), IoU is 0.0\n",
      "for image_374, groud truth:tensor([0.3566, 0.1034, 0.3812, 0.1930]), pred:tensor([0.9750, 0.4751, 0.0500, 0.1379]), IoU is 0.0\n",
      "for image_246, groud truth:tensor([0.5171, 0.1453, 0.1247, 0.1299]), pred:tensor([0.6930, 0.1800, 0.1609, 0.2188]), IoU is 0.0\n",
      "for image_135, groud truth:tensor([0.3439, 0.3369, 0.1813, 0.4460]), pred:tensor([0.2773, 0.9561, 0.1734, 0.0878]), IoU is 0.0\n",
      "for image_388, groud truth:tensor([0.3431, 0.0814, 0.1087, 0.0885]), pred:tensor([0.8836, 0.8065, 0.0828, 0.1609]), IoU is 0.0\n",
      "for image_298, groud truth:tensor([0.3988, 0.2726, 0.0762, 0.1416]), pred:tensor([0.0484, 0.0787, 0.0969, 0.1573]), IoU is 0.0\n",
      "for image_328, groud truth:tensor([0.4632, 0.1719, 0.1699, 0.1061]), pred:tensor([0.9781, 0.6205, 0.0437, 0.1017]), IoU is 0.0\n",
      "for image_145, groud truth:tensor([0.1556, 0.1034, 0.1003, 0.0908]), pred:tensor([0.7367, 0.1780, 0.1922, 0.2352]), IoU is 0.0\n",
      "for image_26, groud truth:tensor([0.3743, 0.1535, 0.3281, 0.2874]), pred:tensor([0.7250, 0.2204, 0.5500, 0.4408]), IoU is 0.0816253125667572\n",
      "for image_163, groud truth:tensor([0.1675, 0.7424, 0.1247, 0.4775]), pred:tensor([0.9508, 0.0492, 0.0984, 0.0984]), IoU is 0.0\n",
      "for image_200, groud truth:tensor([0.4748, 0.1854, 0.3180, 0.3636]), pred:tensor([0.0375, 0.6876, 0.0750, 0.1524]), IoU is 0.0\n",
      "for image_250, groud truth:tensor([0.6260, 0.0985, 0.0944, 0.1169]), pred:tensor([0.9516, 0.0493, 0.0969, 0.0986]), IoU is 0.0\n",
      "for image_180, groud truth:tensor([0.3464, 0.5309, 0.5703, 0.4049]), pred:tensor([0.9547, 0.0766, 0.0906, 0.1343]), IoU is 0.0\n",
      "for image_381, groud truth:tensor([0.3105, 0.8162, 0.1159, 0.1292]), pred:tensor([0.8180, 0.9460, 0.0234, 0.0664]), IoU is 0.0\n",
      "for image_278, groud truth:tensor([0.2878, 0.0760, 0.0358, 0.0680]), pred:tensor([0.0570, 0.4929, 0.0859, 0.1041]), IoU is 0.0\n",
      "for image_150, groud truth:tensor([0.5239, 0.4229, 0.0843, 0.0885]), pred:tensor([0.7414, 0.8231, 0.5172, 0.3538]), IoU is 0.0\n",
      "for image_4, groud truth:tensor([0.2218, 0.1087, 0.0355, 0.0378]), pred:tensor([0.9812, 0.0701, 0.0375, 0.1041]), IoU is 0.0\n",
      "for image_56, groud truth:tensor([0.7171, 0.1955, 0.0853, 0.2699]), pred:tensor([0.9523, 0.0493, 0.0953, 0.0986]), IoU is 0.0\n",
      "for image_359, groud truth:tensor([0.4748, 0.3778, 0.4242, 0.2308]), pred:tensor([0.9531, 0.0492, 0.0938, 0.0984]), IoU is 0.0\n",
      "for image_51, groud truth:tensor([0.5234, 0.0863, 0.0859, 0.1068]), pred:tensor([0.9594, 0.0489, 0.0812, 0.0979]), IoU is 0.0\n",
      "for image_382, groud truth:tensor([0.1961, 0.1353, 0.1351, 0.2152]), pred:tensor([0.9461, 0.0495, 0.1078, 0.0990]), IoU is 0.0\n",
      "for image_322, groud truth:tensor([0.3499, 0.4352, 0.6543, 0.3796]), pred:tensor([0.9516, 0.0479, 0.0969, 0.0958]), IoU is 0.0\n",
      "for image_399, groud truth:tensor([0.5731, 0.4611, 0.1188, 0.1188]), pred:tensor([0.0469, 0.9342, 0.0938, 0.1317]), IoU is 0.0\n",
      "for image_77, groud truth:tensor([0.4876, 0.6436, 0.5410, 0.3900]), pred:tensor([0.4203, 0.1766, 0.2812, 0.2531]), IoU is 0.0\n",
      "for image_128, groud truth:tensor([0.4406, 0.0635, 0.1188, 0.0918]), pred:tensor([0.9734, 0.9723, 0.0531, 0.0554]), IoU is 0.0\n",
      "for image_84, groud truth:tensor([0.4570, 0.4666, 0.5326, 0.4971]), pred:tensor([0.0875, 0.1521, 0.0531, 0.0793]), IoU is 0.0\n",
      "for image_360, groud truth:tensor([0.3166, 0.1577, 0.2614, 0.1774]), pred:tensor([0.9586, 0.0756, 0.0828, 0.1385]), IoU is 0.0\n",
      "for image_74, groud truth:tensor([0.4894, 0.1927, 0.3825, 0.3021]), pred:tensor([0.6758, 0.0867, 0.0828, 0.1734]), IoU is 0.049267273396253586\n",
      "for image_211, groud truth:tensor([0.4609, 0.3354, 0.1322, 0.1566]), pred:tensor([0.6336, 0.8535, 0.7328, 0.2930]), IoU is 0.0\n",
      "for image_118, groud truth:tensor([0.3280, 0.1605, 0.3473, 0.1341]), pred:tensor([0.9445, 0.0494, 0.1109, 0.0989]), IoU is 0.0\n",
      "for image_357, groud truth:tensor([0.4015, 0.1732, 0.0518, 0.1185]), pred:tensor([0.9523, 0.0491, 0.0953, 0.0981]), IoU is 0.0\n",
      "for image_346, groud truth:tensor([0.1328, 0.1110, 0.1263, 0.1270]), pred:tensor([0.5711, 0.4439, 0.1141, 0.2004]), IoU is 0.0\n",
      "for image_5, groud truth:tensor([0.2715, 0.1978, 0.0990, 0.1325]), pred:tensor([0.9461, 0.0495, 0.1078, 0.0990]), IoU is 0.0\n",
      "for image_109, groud truth:tensor([0.3805, 0.3970, 0.3906, 0.2367]), pred:tensor([0.9508, 0.0492, 0.0984, 0.0984]), IoU is 0.0\n",
      "for image_294, groud truth:tensor([0.3354, 0.3989, 0.0641, 0.1006]), pred:tensor([0.9719, 0.0487, 0.0562, 0.0974]), IoU is 0.0\n",
      "for image_350, groud truth:tensor([0.5216, 0.5355, 0.0550, 0.1061]), pred:tensor([0.7531, 0.1322, 0.1219, 0.1699]), IoU is 0.0\n",
      "for image_202, groud truth:tensor([0.4938, 0.0947, 0.0703, 0.0397]), pred:tensor([0.2781, 0.7375, 0.5562, 0.5250]), IoU is 0.0\n",
      "for image_247, groud truth:tensor([0.3304, 0.1986, 0.3203, 0.2155]), pred:tensor([0.9633, 0.1763, 0.0734, 0.1474]), IoU is 0.0\n",
      "for image_80, groud truth:tensor([0.3275, 0.1375, 0.0801, 0.0882]), pred:tensor([0.9633, 0.8451, 0.0703, 0.1095]), IoU is 0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ground_truth_dir = r'../data/transfer_learning/test/'\n",
    "prediction_dir = r'runs/detect/exp28/labels/'\n",
    "iou_list = []\n",
    "\n",
    "# iterate the ground truth directory\n",
    "for root, dirs, files in os.walk(ground_truth_dir):\n",
    "    # check if the file is a .txt file\n",
    "    for file in files:\n",
    "        if '.txt' not in file: \n",
    "            continue\n",
    "        else:\n",
    "            file_prefix = file.split('.')[0]\n",
    "        box1 = get_coord(ground_truth_dir, file)\n",
    "        box2 = get_coord(prediction_dir, file)\n",
    "        iou = float(bbox_iou(box1, box2))\n",
    "        print(f'for {file_prefix}, groud truth:{box1}, pred:{box2}, IoU is {iou}')\n",
    "        iou_list.append(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006351515828372584"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of the iou_list\n",
    "sum(iou_list)/len(iou_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
